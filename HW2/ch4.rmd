---
title: "Assignment 2_conceptual"
author: "Pong Yui Yi Monica SID: 20853295"
date: "2024-11-3"
output: html_document
---
### Question 13

> This question should be answered using the `Weekly` data set, which is part
> of the `ISLR2` package. This data is similar in nature to the `Smarket` data
> from this chapter's lab, except that it contains 1,089 weekly returns for 21
> years, from the beginning of 1990 to the end of 2010.
>
> a. Produce some numerical and graphical summaries of the `Weekly` data. Do
>    there appear to be any patterns?

```{r, message = FALSE, warning = FALSE}
library(MASS)
library(class)
library(tidyverse)
library(corrplot)
library(ISLR2)
library(e1071)
```

```{r}
summary(Weekly)
corrplot(cor(Weekly[, -9]), type = "lower", diag = FALSE, method = "ellipse")
```

Volume is strongly positively correlated with Year. Other correlations are
week, but Lag1 is negatively correlated with Lag2 but positively correlated
with Lag3.

> b. Use the full data set to perform a logistic regression with `Direction` as
>    the response and the five lag variables plus `Volume` as predictors. Use
>    the summary function to print the results. Do any of the predictors appear
>    to be statistically significant? If so, which ones?

```{r}
fit <- glm(
  Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
  data = Weekly,
  family = binomial
)
summary(fit)
```

Lag2 is significant.

> c. Compute the confusion matrix and overall fraction of correct predictions.
>    Explain what the confusion matrix is telling you about the types of
>    mistakes made by logistic regression.

```{r}
contrasts(Weekly$Direction)
pred <- predict(fit, type = "response") > 0.5
(t <- table(ifelse(pred, "Up (pred)", "Down (pred)"), Weekly$Direction))
sum(diag(t)) / sum(t)
```

The overall fraction of correct predictions is 0.56. Although logistic
regression correctly predicts upwards movements well, it incorrectly predicts
most downwards movements as up.

> d. Now fit the logistic regression model using a training data period from
>    1990 to 2008, with `Lag2` as the only predictor. Compute the confusion
>    matrix and the overall fraction of correct predictions for the held out
>    data (that is, the data from 2009 and 2010).

```{r}
train <- Weekly$Year < 2009

fit <- glm(Direction ~ Lag2, data = Weekly[train, ], family = binomial)
pred <- predict(fit, Weekly[!train, ], type = "response") > 0.5
(t <- table(ifelse(pred, "Up (pred)", "Down (pred)"), Weekly[!train, ]$Direction))
sum(diag(t)) / sum(t)
```

> e. Repeat (d) using LDA.

```{r}
fit <- lda(Direction ~ Lag2, data = Weekly[train, ])
pred <- predict(fit, Weekly[!train, ], type = "response")$class
(t <- table(pred, Weekly[!train, ]$Direction))
sum(diag(t)) / sum(t)
```

> f. Repeat (d) using QDA.

```{r}
fit <- qda(Direction ~ Lag2, data = Weekly[train, ])
pred <- predict(fit, Weekly[!train, ], type = "response")$class
(t <- table(pred, Weekly[!train, ]$Direction))
sum(diag(t)) / sum(t)
```

> g. Repeat (d) using KNN with $K = 1$.

```{r}
fit <- knn(
  Weekly[train, "Lag2", drop = FALSE],
  Weekly[!train, "Lag2", drop = FALSE],
  Weekly$Direction[train]
)
(t <- table(fit, Weekly[!train, ]$Direction))
sum(diag(t)) / sum(t)
```

> h. Repeat (d) using naive Bayes.

```{r}
fit <- naiveBayes(Direction ~ Lag2, data = Weekly, subset = train)
pred <- predict(fit, Weekly[!train, ], type = "class")
(t <- table(pred, Weekly[!train, ]$Direction))
sum(diag(t)) / sum(t)
```

> i. Which of these methods appears to provide the best results on this data?

Logistic regression and LDA are the best performing.

> j. Experiment with different combinations of predictors, including possible
>    transformations and interactions, for each of the methods. Report the
>    variables, method, and associated confusion matrix that appears to provide
>    the best results on the held out data. Note that you should also
>    experiment with values for $K$ in the KNN classifier.

```{r}
fit <- glm(Direction ~ Lag1, data = Weekly[train, ], family = binomial)
pred <- predict(fit, Weekly[!train, ], type = "response") > 0.5
mean(ifelse(pred, "Up", "Down") == Weekly[!train, ]$Direction)

fit <- glm(Direction ~ Lag3, data = Weekly[train, ], family = binomial)
pred <- predict(fit, Weekly[!train, ], type = "response") > 0.5
mean(ifelse(pred, "Up", "Down") == Weekly[!train, ]$Direction)

fit <- glm(Direction ~Lag4, data = Weekly[train, ], family = binomial)
pred <- predict(fit, Weekly[!train, ], type = "response") > 0.5
mean(ifelse(pred, "Up", "Down") == Weekly[!train, ]$Direction)

fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4, data = Weekly[train, ], family = binomial)
pred <- predict(fit, Weekly[!train, ], type = "response") > 0.5
mean(ifelse(pred, "Up", "Down") == Weekly[!train, ]$Direction)

fit <- glm(Direction ~ Lag1 * Lag2 * Lag3 * Lag4, data = Weekly[train, ], family = binomial)
pred <- predict(fit, Weekly[!train, ], type = "response") > 0.5
mean(ifelse(pred, "Up", "Down") == Weekly[!train, ]$Direction)

fit <- lda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4,data = Weekly[train, ])
pred <- predict(fit, Weekly[!train, ], type = "response")$class
mean(pred == Weekly[!train, ]$Direction)

fit <- qda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4, data = Weekly[train, ])
pred <- predict(fit, Weekly[!train, ], type = "response")$class
mean(pred == Weekly[!train, ]$Direction)

fit <- naiveBayes(Direction ~ Lag1 + Lag2 + Lag3 + Lag4, data = Weekly[train, ])
pred <- predict(fit, Weekly[!train, ], type = "class")
mean(pred == Weekly[!train, ]$Direction)

set.seed(1)
res <- sapply(1:30, function(k) {
  fit <- knn(
    Weekly[train, 2:4, drop = FALSE],
    Weekly[!train, 2:4, drop = FALSE],
    Weekly$Direction[train],
    k = k
  )
  mean(fit == Weekly[!train, ]$Direction)
})
plot(1:30, res, type = "o", xlab = "k", ylab = "Fraction correct")
(k <- which.max(res))

fit <- knn(
  Weekly[train, 2:4, drop = FALSE],
  Weekly[!train, 2:4, drop = FALSE],
  Weekly$Direction[train],
  k = k
)
table(fit, Weekly[!train, ]$Direction)
mean(fit == Weekly[!train, ]$Direction)
```

KNN using the first 3 Lag variables performs marginally better than logistic
regression with `Lag2` if we tune $k$ to be $k = 26$.

### Question 14

> In this problem, you will develop a model to predict whether a given car gets
> high or low gas mileage based on the `Auto` data set.
>
> a. Create a binary variable, `mpg01`, that contains a 1 if `mpg` contains a
>    value above its median, and a 0 if `mpg` contains a value below its
>    median. You can compute the median using the `median()` function. Note you
>    may find it helpful to use the `data.frame()` function to create a single
>    data set containing both `mpg01` and the other `Auto` variables.

```{r}
x <- cbind(Auto[, -1], data.frame("mpg01" = Auto$mpg > median(Auto$mpg)))
```

> b. Explore the data graphically in order to investigate the association
>    between `mpg01` and the other features. Which of the other features seem
>    most likely to be useful in predicting `mpg01`? Scatterplots and boxplots
>    may be useful tools to answer this question. Describe your findings.

```{r}
par(mfrow = c(2, 4))
for (i in 1:7) hist(x[, i], breaks = 20, main = colnames(x)[i])

par(mfrow = c(2, 4))
for (i in 1:7) boxplot(x[, i] ~ x$mpg01, main = colnames(x)[i])

pairs(x[, 1:7])
```

Most variables show an association with `mpg01` category, and several
variables are colinear.

> c. Split the data into a training set and a test set.

```{r}
set.seed(1)
train <- sample(seq_len(nrow(x)), nrow(x) * 2/3)
```

> d. Perform LDA on the training data in order to predict `mpg01` using the
>    variables that seemed most associated with `mpg01` in (b). What is the
>    test error of the model obtained?

```{r}
sort(sapply(1:7, function(i) {
  setNames(abs(t.test(x[, i] ~ x$mpg01)$statistic), colnames(x)[i])
}))

fit <- lda(mpg01 ~ cylinders + weight + displacement, data = x[train, ])
pred <- predict(fit, x[-train, ], type = "response")$class
mean(pred != x[-train, ]$mpg01)
```

> e. Perform QDA on the training data in order to predict `mpg01` using the
>    variables that seemed most associated with `mpg01` in (b). What is the
>    test error of the model obtained?

```{r}
fit <- qda(mpg01 ~ cylinders + weight + displacement, data = x[train, ])
pred <- predict(fit, x[-train, ], type = "response")$class
mean(pred != x[-train, ]$mpg01)
```

> f. Perform logistic regression on the training data in order to predict
>    `mpg01` using the variables that seemed most associated with `mpg01` in
>    (b). What is the test error of the model obtained?

```{r}
fit <- glm(mpg01 ~ cylinders + weight + displacement, data = x[train, ], family = binomial)
pred <- predict(fit, x[-train, ], type = "response") > 0.5
mean(pred != x[-train, ]$mpg01)
```

> g. Perform naive Bayes on the training data in order to predict `mpg01` using
>    the variables that seemed most associated with `mpg01` in (b). What is the
>    test error of the model obtained?

```{r}
fit <- naiveBayes(mpg01 ~ cylinders + weight + displacement, data = x[train, ])
pred <- predict(fit, x[-train, ], type = "class")
mean(pred != x[-train, ]$mpg01)
```

> h. Perform KNN on the training data, with several values of $K$, in order to
>    predict `mpg01`. Use only the variables that seemed most associated with
>    `mpg01` in (b). What test errors do you obtain? Which value of $K$ seems
>    to perform the best on this data set?

```{r}
res <- sapply(1:50, function(k) {
  fit <- knn(x[train, c(1, 4, 2)], x[-train, c(1, 4, 2)], x$mpg01[train], k = k)
  mean(fit != x[-train, ]$mpg01)
})
names(res) <- 1:50
plot(res, type = "o")
res[which.min(res)]
```

For the models tested here, $k = 32$ appears to perform best. QDA has a lower
error rate overall, performing slightly better than LDA.

### Question 15

> This problem involves writing functions.
>
> a. Write a function, `Power()`, that prints out the result of raising 2 to
>    the 3rd power. In other words, your function should compute $2^3$ and
>    print out the results.
>
>    _Hint: Recall that `x^a` raises `x` to the power `a`. Use the `print()`_
>    _function to output the result._

```{r}
Power <- function() print(2^3)
```

> b. Create a new function, `Power2()`, that allows you to pass any two
>    numbers, `x` and `a`, and prints out the value of `x^a`. You can do this
>    by beginning your function with the line
>    ```r
>    > Power2=function(x,a) {
>    ```
>    You should be able to call your function by entering, for instance,
>    ```r
>    > Power2(3, 8)
>    ```
>    on the command line. This should output the value of $3^8$, namely, 6,561.

```{r}
Power2 <- function(x, a) print(x^a)
```

> c. Using the `Power2()` function that you just wrote, compute $10^3$,
>    $8^{17}$, and $131^3$.

```{r}
c(Power2(10, 3), Power2(8, 17), Power2(131, 3))
```

> d. Now create a new function, `Power3()`, that actually returns the result
>    `x^a` as an `R` object, rather than simply printing it to the screen. That
>    is, if you store the value `x^a` in an object called result within your
>    function, then you can simply `return()` this result, using the following
>    line:
>    ```r
>    > return(result)
>    ```
>    The line above should be the last line in your function, before the `}`
>    symbol.

```{r}
Power3 <- function(x, a) {
  result <- x^a
  return(result)
}
```

> e. Now using the `Power3()` function, create a plot of $f(x) = x^2$. The
>    $x$-axis should display a range of integers from 1 to 10, and the $y$-axis
>    should display $x^2$. Label the axes appropriately, and use an appropriate
>    title for the figure. Consider displaying either the $x$-axis, the
>    $y$-axis, or both on the log-scale. You can do this by using `log = "x"`,
>    `log = "y"`, or `log = "xy"` as arguments to the `plot()` function.

```{r}
plot(1:10, Power3(1:10, 2), 
  xlab = "x", 
  ylab = expression(paste("x"^"2")),
  log = "y"
)
```

> f. Create a function, `PlotPower()`, that allows you to create a plot of `x`
>    against `x^a` for a fixed `a` and for a range of values of `x`. For
>    instance, if you call
>    ```r
>    > PlotPower(1:10, 3)
>    ```
>    then a plot should be created with an $x$-axis taking on values 
>    $1,2,...,10$, and a $y$-axis taking on values $1^3,2^3,...,10^3$.

```{r}
PlotPower <- function(x, a, log = "y") {
  plot(x, Power3(x, a),
    xlab = "x", 
    ylab = substitute("x"^a, list(a = a)),
    log = log
  )
}

PlotPower(1:10, 3)
```

### Question 13

> Using the `Boston` data set, fit classification models in order to predict
> whether a given census tract has a crime rate above or below the median.
> Explore logistic regression, LDA, naive Bayes and KNN models using various
> sub-sets of the predictors. Describe your findings.
>
> _Hint: You will have to create the response variable yourself, using the_
> _variables that are contained in the `Boston` data set._

```{r}
x <- cbind(
  ISLR2::Boston[, -1], 
  data.frame("highcrim" = Boston$crim > median(Boston$crim))
)
set.seed(1)
train <- sample(seq_len(nrow(x)), nrow(x) * 2/3)
```

We can find the most associated variables by performing wilcox tests.

```{r}
ord <- order(sapply(1:12, function(i) {
  p <- wilcox.test(as.numeric(x[train, i]) ~ x[train, ]$highcrim)$p.value
  setNames(log10(p), colnames(x)[i])
}))
ord <- names(x)[ord]
ord
```

Variables `nox` (nitrogen oxides concentration) followed by `dis` (distance to
employment center) appear to be most associated with high crime.

Let's reorder columns by those most associated with highcrim (in the training
data)

```{r}
x <- x[, c(ord, "highcrim")]
```

Let's look at univariate associations with `highcrim` (in the training data)

```{r}
x[train, ] |>
  pivot_longer(!highcrim) |>
  mutate(name = factor(name, levels = ord)) |>
  ggplot(aes(highcrim, value)) + 
  geom_boxplot() + 
  facet_wrap(~name, scale = "free")
```

Fit lda, logistic regression, naive Bayes and KNN models (with k = 1..50) for a
set of specific predictors and return the error rate. We fit models using
increasing numbers of predictors: column 1, then columns 1 and 2 etc.

```{r}
fit_models <- function(cols, k_vals = 1:50) {
  dat_train <- x[train, cols, drop = FALSE]
  dat_test <- x[-train, cols, drop = FALSE]

  fit <- lda(x$highcrim[train] ~ ., data = dat_train)
  pred <- predict(fit, dat_test, type = "response")$class
  lda_err <- mean(pred != x$highcrim[-train])

  fit <- glm(x$highcrim[train] ~ ., data = dat_train, family = binomial)
  pred <- predict(fit, dat_test, type = "response") > 0.5
  logreg_err <- mean(pred != x$highcrim[-train])

  fit <- naiveBayes(x$highcrim[train] ~ ., data = dat_train)
  pred <- predict(fit, dat_test, type = "class")
  nb_err <- mean(pred != x$highcrim[-train])

  res <- sapply(k_vals, function(k) {
    fit <- knn(dat_train, dat_test, x$highcrim[train], k = k)
    mean(fit != x$highcrim[-train])
  })
  knn_err <- min(res)

  c("LDA" = lda_err, "LR" = logreg_err, "NB" = nb_err, "KNN" = knn_err)
}
```

```{r}
res <- sapply(1:12, function(max) fit_models(1:max))
res <- as_tibble(t(res))
res$n_var <- 1:12
pivot_longer(res, cols = !n_var) |>
  ggplot(aes(n_var, value, col = name)) + 
  geom_line() + 
  xlab("Number of predictors") + 
  ylab("Error rate")
```

KNN appears to perform better (if we tune $k$) for all numbers of predictors.

```{r}
fit <- knn(
  x[train, "nox", drop = FALSE],
  x[-train, "nox", drop = FALSE],
  x$highcrim[train],
  k = 1
)
table(fit, x[-train, ]$highcrim)
mean(fit != x[-train, ]$highcrim) * 100
```

Surprisingly, the best model (with an error rate of <5%) uses $k = 1$ and
assigns crime rate categories based on the town with the single most similar
nitrogen oxide concentration (`nox`). This might be, for example, because nearby
towns have similar crime rates, and we can obtain good predictions by predicting
crime rate based on a nearby town.

But what if we only consider $k = 20$.

```{r}
res <- sapply(1:12, function(max) fit_models(1:max, k_vals = 20))
res <- as_tibble(t(res))
res$n_var <- 1:12
pivot_longer(res, cols = !n_var) |>
  ggplot(aes(n_var, value, col = name)) +
  geom_line() +
  xlab("Number of predictors") +
  ylab("Error rate")
```

KNN still performs best with a single predictor (`nox`), but logistic regression
with 12 predictors also performs well and has an error rate of ~12%.

```{r}
vars <- names(x)[1:12]
dat_train <- x[train, vars]
dat_test <- x[-train, vars]

fit <- glm(x$highcrim[train] ~ ., data = dat_train, family = binomial)
pred <- predict(fit, dat_test, type = "response") > 0.5
table(pred, x[-train, ]$highcrim)
mean(pred != x$highcrim[-train]) * 100
summary(fit)
```